{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "33617e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"https://www.naver.com/\"\n",
    "html = urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "title = soup.select(\"#NM_set_home_btn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4cba8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "li = []\n",
    "pnum = 1\n",
    "url = \"https://news.daum.net/breakingnews?page=\"\n",
    "url += str(pnum)\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "newslist = soup.select('.tit_thumb .link_txt')\n",
    "presss = soup.select('.info_news')\n",
    "times = soup.select('.info_time')\n",
    "bodys = soup.select('.desc_thumb .link_txt')\n",
    "\n",
    "for i in range(len(presss)):\n",
    "    temp = []\n",
    "    title = newslist[i].get_text()\n",
    "    url = newslist[i]['href']\n",
    "    press = presss[i].get_text()[:-8]\n",
    "    time = times[i].get_text()\n",
    "    body = bodys[i].text.strip()\n",
    "    temp.append(title)\n",
    "    temp.append(press)\n",
    "    temp.append(time)\n",
    "    temp.append(body)\n",
    "    temp.append(url)\n",
    "    li.append(temp)\n",
    "\n",
    "f = open('news.csv','w',encoding='utf-8',newline='')\n",
    "csvwriter = csv.writer(f)\n",
    "header = ['title','press','time','headline','url']\n",
    "csvwriter.writerow(header)\n",
    "for i in li:\n",
    "    csvwriter.writerow(i)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d616ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import urllib.parse\n",
    "from urllib.request import urlopen,Request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "df017bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input page number: 1\n"
     ]
    }
   ],
   "source": [
    "lit = []\n",
    "pagenum = int(input(\"input page number: \"))\n",
    "for i in range(1, pagenum+1):\n",
    "    url='https://comic.naver.com/webtoon/list.nhn?titleId=335885&page='+str(i)\n",
    "    html=urllib.request.urlopen(url).read()\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    titletd = soup.select('.title a')\n",
    "    for j in range(10):\n",
    "        temp = []\n",
    "        title = titletd[j].get_text()\n",
    "        titlelink = 'https://comic.naver.com'+titletd[j]['href']\n",
    "        stars = soup.select('.rating_type')[j].strong.get_text()\n",
    "        temp.append(title)\n",
    "        temp.append(titlelink)\n",
    "        temp.append(stars)\n",
    "        lit.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ccfd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = \"https://www.coupang.com/np/categories/497135?page=1\"\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup=BeautifulSoup(html,'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a3a5b9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input blogs number: 30\n"
     ]
    }
   ],
   "source": [
    "lit2 = []\n",
    "serch = input()\n",
    "purl = urllib.parse.quote_plus(serch)\n",
    "url = f\"https://search.naver.com/search.naver?query={purl}&nso=&where=blog&sm=tab_viw.all\"\n",
    "headers = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36\"}\n",
    "pnum = int(input(\"input blogs number(max 30): \"))\n",
    "for i in range(1):\n",
    "    #html = urllib.request.urlopen(Request(url, headers={'User-Agent':\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36\"})).read()\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    for j in range(pnum):\n",
    "        temp = []\n",
    "        date = soup.select('.sub_time.sub_txt')[j].get_text()\n",
    "        where = soup.select('.sub_txt.sub_name')[j].get_text()\n",
    "        tit = soup.select('.api_txt_lines.total_tit')[j].get_text()\n",
    "        hline = soup.select('.api_txt_lines.dsc_txt')[j].get_text()\n",
    "        link = soup.select('.api_txt_lines.total_tit')[j]['href']\n",
    "        temp.append(tit)\n",
    "        temp.append(date)\n",
    "        temp.append(where)\n",
    "        temp.append(hline)\n",
    "        temp.append(link)\n",
    "        lit2.append(temp)\n",
    "\n",
    "f = open(serch+\".csv\",\"w\",encoding=\"utf-8\",newline=\"\")\n",
    "csvwriter = csv.writer(f)\n",
    "header=['Title','date','from','headline','url']\n",
    "csvwriter.writerow(header)\n",
    "for i in lit2:\n",
    "    csvwriter.writerow(i)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ed2f3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"tmp1.csv\",\"w\",encoding=\"utf-8\",newline=\"\")\n",
    "csvwriter=csv.writer(f)\n",
    "header=['Title','url','rate']\n",
    "csvwriter.writerow(header)\n",
    "for i in lit:\n",
    "    csvwriter.writerow(i)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac030f09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>url</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250화 상식씨!</td>\n",
       "      <td>https://comic.naver.com/webtoon/detail.nhn?tit...</td>\n",
       "      <td>9.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249화 이해</td>\n",
       "      <td>https://comic.naver.com/webtoon/detail.nhn?tit...</td>\n",
       "      <td>9.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248화 결재타이밍</td>\n",
       "      <td>https://comic.naver.com/webtoon/detail.nhn?tit...</td>\n",
       "      <td>9.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247화 남동생</td>\n",
       "      <td>https://comic.naver.com/webtoon/detail.nhn?tit...</td>\n",
       "      <td>9.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246화 도시농업</td>\n",
       "      <td>https://comic.naver.com/webtoon/detail.nhn?tit...</td>\n",
       "      <td>9.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Title                                                url  rate\n",
       "0   250화 상식씨!  https://comic.naver.com/webtoon/detail.nhn?tit...  9.96\n",
       "1     249화 이해  https://comic.naver.com/webtoon/detail.nhn?tit...  9.96\n",
       "2  248화 결재타이밍  https://comic.naver.com/webtoon/detail.nhn?tit...  9.96\n",
       "3    247화 남동생  https://comic.naver.com/webtoon/detail.nhn?tit...  9.96\n",
       "4   246화 도시농업  https://comic.naver.com/webtoon/detail.nhn?tit...  9.96"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('tmp1.csv')\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
